# ThermoWatch-AE: Convolutional Autoencoders for Machine Temperature Anomaly Detection

> **Short pitch**: An unsupervised anomaly detection pipeline using 1D convolutional autoencoders to model normal machine temperature behavior and flag outliers via reconstruction error.

---

## ğŸ§© Project Overview
**ThermoWatch-AE** is a deep learning project focused on **detecting anomalies in industrial machine temperature data** using **Convolutional Autoencoders (ConvAEs)**.  
It applies unsupervised learning to identify potential system failures by learning normal operating patterns and flagging deviations based on reconstruction error.

This project demonstrates:
- Real-world time-series data processing  
- Model design and hyperparameter tuning in PyTorch  
- Regularization, learning-rate scheduling, and loss optimization  
- Quantitative evaluation and clear visualization of results  

---

## ğŸ“Š Dataset
- **Source:** *Numenta Anomaly Benchmark (NAB)* â€” *Machine Temperature System Failure*  
- **File:** `machine_temperature_system_failure.csv`  
- **Columns:** `timestamp`, `value`  
- **Statistics:**  
  - 22,695 data points  
  - Value range: 2.08 â€“ 108.51  
  - Mean â‰ˆ 85.93, Std â‰ˆ 13.75  

---

## âš™ï¸ Approach Overview

### 1. Data Preprocessing
- Applied **Min-Max scaling** to normalize temperature values between 0 and 1.  
- Created fixed-length **sliding windows (size = 30)** for temporal modeling.  
- Sequential split into **train (70%)**, **validation (15%)**, and **test (15%)** sets.  

---

### 2. Model Architectures

| Model | Encoder | Decoder | Activation | Params | Highlights |
|--------|----------|----------|-------------|-----------|-------------|
| **ConvAE1** | 1â†’16â†’8 | 8â†’16â†’1 | LeakyReLU(0.1), Dropout(0.1), Sigmoid | ~905 | Compact baseline |
| **ConvAE2** | 1â†’32â†’16â†’8 | 8â†’16â†’32â†’1 | LeakyReLU(0.1), Dropout(0.1â€“0.2), Sigmoid | ~5.2K | **Best performing model** |
| **ConvAE3** | 1â†’64â†’32 | 32â†’64â†’1 | LeakyReLU + ReLU, Dropout(0.2) | ~12.8K | Deeper architecture |

---

### 3. Training and Optimization
- **Loss:** Mean Squared Error (MSELoss)  
- **Optimizer:** Adam with weight decay = 1e-5  
- **Learning-Rate Scheduler:** StepLR(step_size = 50, gamma = 0.5)  
- **Hyperparameter tuning:**  
  - Batch sizes: 32 â€“ 256  
  - Learning rates: 1e-3 to 5e-5  
  - Epochs: 100 â€“ 250  
- **Model selection:** Based on minimum validation loss.  
- Final model weights saved as **`a2_part2_yavarkha_mohdsaad.pth`**.  

---

### 4. Anomaly Detection
- Computed **reconstruction error** between input and output sequences.  
- Defined anomaly threshold at the **95th percentile** of training reconstruction errors.  
- Windows exceeding this threshold were flagged as **anomalous behavior**.  

---

## ğŸ“ˆ Results

| Metric | ConvAE2 (Best Model) |
|--------|----------------------|
| Validation Loss | **0.000055** |
| Training Loss | **0.000112** |
| MAE | **0.007117** |
| RMSE | **0.010865** |
| RÂ² Score | **0.997051** |

These results show that the model effectively reconstructs normal temperature sequences while maintaining high sensitivity to abnormal fluctuations.

---

## ğŸ“‰ Visualizations
The project includes clear and interpretable plots:
- Temperature variation over time  
- Histograms and boxplots of raw values  
- Training vs. validation loss curves  
- Reconstruction error distribution with threshold line  
- Original vs. reconstructed signal comparisons  

---

## ğŸ§  Reproducibility Summary

```python
# 1. Load and scale dataset
# 2. Create windowed sequences (length=30)
# 3. Define ConvAE1, ConvAE2, ConvAE3 in PyTorch
# 4. Train with MSELoss + Adam + StepLR scheduler
# 5. Evaluate on validation data and save best model
# 6. Compute reconstruction errors on test data
# 7. Detect anomalies using 95th percentile threshold
